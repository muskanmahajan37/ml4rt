#!/bin/tcsh

#SBATCH --job-name="make_saliency_maps_all_targets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=16G
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=24:00:00
#SBATCH --array=1-4
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=make_saliency_maps_all_targets_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_standalone/ml4rt"
set TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_models/experiment06"
set EXAMPLE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4rt_project/examples/non_tropical_sites"

set DENSE_LAYER_COUNTS=(3 3 4 2)
set DENSE_LAYER_DROPOUT_RATES=(0 0.1 0 0.1)
set SCALAR_LOSS_FUNCTION_WEIGHTS=(50 2.5 25 50)

set dense_layer_count=${DENSE_LAYER_COUNTS[$SLURM_ARRAY_TASK_ID]}
set dense_layer_dropout_rate=${DENSE_LAYER_DROPOUT_RATES[$SLURM_ARRAY_TASK_ID]}
set scalar_loss_function_weight=${SCALAR_LOSS_FUNCTION_WEIGHTS[$SLURM_ARRAY_TASK_ID]}

set dense_layer_count_string=`printf "%d" $dense_layer_count`
set dense_layer_dropout_string=`printf "%.3f" $dense_layer_dropout_rate`
set scalar_loss_function_weight_string=`printf "%05.1f" $scalar_loss_function_weight`
set top_model_dir_name="${TOP_MODEL_DIR_NAME}/num-dense-layers=${dense_layer_count_string}_dense-dropout=${dense_layer_dropout_string}_scalar-lf-weight=${scalar_loss_function_weight_string}"

set model_file_names={${top_model_dir_name}/model*.h5}
set model_file_name=${model_file_names[$#model_file_names]}
set model_dir_name=`echo $model_file_name | rev | cut -c 4- | rev`

set PATHLESS_EXAMPLE_ID_FILE_NAMES=("best_and_worst_hr/averaged=0_scaled=0/predictions_high-bias.nc" "best_and_worst_hr/averaged=0_scaled=0/predictions_low-bias.nc" "best_and_worst_hr/averaged=0_scaled=0/predictions_low-absolute-error.nc" "best_and_worst_hr/averaged=0_scaled=1/predictions_high-bias.nc" "best_and_worst_hr/averaged=0_scaled=1/predictions_low-bias.nc" "best_and_worst_hr/averaged=0_scaled=1/predictions_low-absolute-error.nc" "best_and_worst_hr/averaged=1/predictions_high-bias.nc" "best_and_worst_hr/averaged=1/predictions_low-bias.nc" "best_and_worst_hr/averaged=1/predictions_low-absolute-error.nc" "best_and_worst_net_fluxes/predictions_high-bias.nc" "best_and_worst_net_fluxes/predictions_low-bias.nc" "best_and_worst_net_fluxes/predictions_low-absolute-error.nc")
set PATHLESS_SALIENCY_FILE_NAMES=("hr-high-bias_averaged=0_scaled=0.nc" "hr-low-bias_averaged=0_scaled=0.nc" "hr-low-abs-error_averaged=0_scaled=0.nc" "hr-high-bias_averaged=0_scaled=1.nc" "hr-low-bias_averaged=0_scaled=1.nc" "hr-low-abs-error_averaged=0_scaled=1.nc" "hr-high-bias_averaged=1.nc" "hr-low-bias_averaged=1.nc" "hr-low-abs-error_averaged=1.nc" "flux-high-bias.nc" "flux-low-bias.nc" "flux-low-abs-error.nc")

set i=1

while ($i <= ${#PATHLESS_EXAMPLE_ID_FILE_NAMES})
    python3 -u "${CODE_DIR_NAME}/make_saliency_maps_all_targets.py" \
    --input_model_file_name="${model_file_name}" \
    --input_example_dir_name="${EXAMPLE_DIR_NAME}" \
    --input_example_id_file_name="${model_dir_name}/validation/${PATHLESS_EXAMPLE_ID_FILE_NAMES[$i]}" \
    --ideal_activation=1000 \
    --scalar_output_layer_name="dense_output" \
    --vector_output_layer_name="conv_output" \
    --output_saliency_file_name="${model_dir_name}/validation/saliency/${PATHLESS_SALIENCY_FILE_NAMES[$i]}"

    @ i = $i + 1
end
